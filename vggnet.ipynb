{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM8kdaJVSDS/72AZIo6hKfR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"glx6YinYaN7T","executionInfo":{"status":"ok","timestamp":1732571781566,"user_tz":480,"elapsed":16614,"user":{"displayName":"sai au","userId":"00187018978915966265"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision import models\n","from torch.utils.data import DataLoader\n","from PIL import Image\n","import requests\n","from io import BytesIO"]},{"cell_type":"code","source":["# Define the transformations for the CIFAR-10 dataset\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  # VGG expects 224x224 input size\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n"],"metadata":{"id":"OF1jpapXaUrC","executionInfo":{"status":"ok","timestamp":1732571784484,"user_tz":480,"elapsed":336,"user":{"displayName":"sai au","userId":"00187018978915966265"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Load CIFAR-10 dataset\n","train_data = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n","test_data = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n","\n","train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4)\n","test_dataloader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=4)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ArxC29y2aYc9","executionInfo":{"status":"ok","timestamp":1732571810542,"user_tz":480,"elapsed":23644,"user":{"displayName":"sai au","userId":"00187018978915966265"}},"outputId":"342ee2e6-a4f4-4cdc-9e30-8c5e5cebb5b6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170M/170M [00:18<00:00, 9.09MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Define the VGGNet model (using VGG16 as an example)\n","class VGGNet(nn.Module):\n","    def __init__(self):\n","        super(VGGNet, self).__init__()\n","        self.vgg = models.vgg16(pretrained=True)  # Load pre-trained VGG16\n","        self.vgg.classifier[6] = nn.Linear(4096, 10)  # Change the final layer to match CIFAR-10 classes\n","\n","    def forward(self, x):\n","        return self.vgg(x)"],"metadata":{"id":"CuVieHonaga5","executionInfo":{"status":"ok","timestamp":1732571814220,"user_tz":480,"elapsed":1028,"user":{"displayName":"sai au","userId":"00187018978915966265"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Initialize the model, loss function, and optimizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = VGGNet().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gOuFrC6tamTu","executionInfo":{"status":"ok","timestamp":1732571829491,"user_tz":480,"elapsed":12910,"user":{"displayName":"sai au","userId":"00187018978915966265"}},"outputId":"422067d7-813a-49ba-8aec-60b2d46a8566"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","100%|██████████| 528M/528M [00:09<00:00, 59.1MB/s]\n"]}]},{"cell_type":"code","source":["# Training the model\n","for epoch in range(5):  # Train for a number of epochs\n","    print(f'Training epoch: {epoch + 1}...')\n","    running_loss = 0.0\n","\n","    model.train()  # Set the model to training mode\n","    for i, data in enumerate(train_dataloader):\n","        inputs, labels = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()  # Zero the parameter gradients\n","\n","        outputs = model(inputs)  # Forward pass\n","        if outputs is None:  # Debugging check\n","            print(\"Model output is None\")\n","            continue\n","\n","        loss = criterion(outputs, labels)  # Compute loss\n","        loss.backward()  # Backward pass\n","        optimizer.step()  # Optimize the model parameters\n","\n","        running_loss += loss.item()\n","\n","    print(f'Loss: {running_loss / len(train_dataloader):.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QNH8FyC9atmZ","executionInfo":{"status":"ok","timestamp":1732575294567,"user_tz":480,"elapsed":3462802,"user":{"displayName":"sai au","userId":"00187018978915966265"}},"outputId":"c91d0a9b-fb4c-4f41-fe08-06eae2741d20"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Training epoch: 1...\n","Loss: 0.4657\n","Training epoch: 2...\n","Loss: 0.2234\n","Training epoch: 3...\n","Loss: 0.1444\n","Training epoch: 4...\n","Loss: 0.0967\n","Training epoch: 5...\n","Loss: 0.0643\n"]}]},{"cell_type":"code","source":["# Evaluate the model\n","correct = 0\n","total = 0\n","\n","model.eval()  # Set the model to evaluation mode\n","with torch.no_grad():\n","    for data in test_dataloader:\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","\n","        outputs = model(images)\n","        if outputs is None:  # Debugging check\n","            print(\"Model output is None during evaluation\")\n","            continue\n","\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = (correct / total) * 100\n","print(f'Test Accuracy: {accuracy:.2f}%')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZgKmXBKga0OX","executionInfo":{"status":"ok","timestamp":1732576672452,"user_tz":480,"elapsed":46897,"user":{"displayName":"sai au","userId":"00187018978915966265"}},"outputId":"47f0d0a0-d410-4242-c4bd-d57eb6b7fc3a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 93.22%\n"]}]},{"cell_type":"code","source":["class_names = ['plane','car','bird','cat','deer','dog','frog','horse','ship','truck']"],"metadata":{"id":"q38HrwCLbqs_","executionInfo":{"status":"ok","timestamp":1732576679921,"user_tz":480,"elapsed":1022,"user":{"displayName":"sai au","userId":"00187018978915966265"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["new_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  # Resize to 32x32\n","    transforms.ToTensor(),  # Convert to tensor\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize\n","])\n","\n","# Function to load and transform the image\n","def load_img(img_path):\n","    response = requests.get(img_path)\n","    image = Image.open(BytesIO(response.content))  # Open image from byte data\n","    image = new_transform(image)  # Apply transformations\n","    image = image.unsqueeze(0)  # Add batch dimension\n","    return image\n","\n","# Image URLs\n","image_paths = [\n","    'https://www.nylabone.com/-/media/project/oneweb/nylabone/images/dog101/10-intelligent-dog-breeds/golden-retriever-tongue-out.jpg',\n","    'https://media.gq.com/photos/6508829d305ef4e0229049b3/master/w_2240,c_limit/plane.jpg',\n","    'https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcQjr-6m4fJFTmH4sIqOHIMJbQBTMw4JhG-CcVscjg5N-fDXF6ku',\n","    'https://cdn.speedsize.com/eb8d0010-7300-4129-8a6d-74bc221f9caf/https://www.virginvoyages.com/dam/jcr:820ffd9b-f003-4e99-84f1-cc3e592b9da3/scarlet%20lady-2252x1266.png',\n","    'https://woofwell.com/cdn/shop/files/Golden-Retriever-Health-WoofWell-Breed-Specific-Dog-Supplements_1600x.jpg?v=1621360789',\n","    'https://i.redd.it/f0mauu1qpbz41.jpg',\n","    'https://www.nylabone.com/-/media/project/oneweb/nylabone/images/dog101/top-10-lists/10-intelligent-dog-breeds.jpg?h=318&iar=0&w=720&hash=BDE1A53E84C77A8C1C4DA40F79DE0915'\n","]\n","\n","# Load images\n","images = [load_img(img) for img in image_paths]\n","\n","# Model evaluation\n","model.eval()\n","with torch.no_grad():\n","    for image in images:\n","        image = image.to(device)\n","        outputs = model(image)\n","        _, predicted = torch.max(outputs, 1)\n","        print(f'The prediction: {class_names[predicted.item()]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Pv1DpLLczNs","executionInfo":{"status":"ok","timestamp":1732576688114,"user_tz":480,"elapsed":5734,"user":{"displayName":"sai au","userId":"00187018978915966265"}},"outputId":"d2b30c27-6f5d-4ca5-c197-69438ed8a9b0"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["The prediction: dog\n","The prediction: plane\n","The prediction: cat\n","The prediction: ship\n","The prediction: dog\n","The prediction: ship\n","The prediction: dog\n"]}]}]}